import openai
import json
import numpy as np
from collections import deque

# è¨­å®š API é‡‘é‘°
openai.api_key = "your_openai_api_key"

# **IOIï¼ˆèˆˆè¶£æŒ‡æ¨™ï¼‰èªå¥**
IOI_examples = [
    "ä½ åœ¨å¹¹å˜›", "ä½ é€±æœ«æœ‰ç©ºå—", "ä½ å¹³å¸¸å–œæ­¡åšä»€éº¼", "ä½ æœ‰æ²’æœ‰å–œæ­¡çš„é¤å»³", "ä½ æ˜¯ä¸æ˜¯å¾ˆæœƒèŠå¤©",
    "å“ˆå“ˆå“ˆ", "å¥½å¥½ç¬‘", "æ€éº¼é€™éº¼å¯æ„›", "æˆ‘å€‘ä¸‹æ¬¡å»å“ª", "æˆ‘ä¹Ÿæƒ³è©¦è©¦", "æˆ‘å¯ä»¥å—"
]

# **IODï¼ˆå†·æ·¡æŒ‡æ¨™ï¼‰èªå¥**
IOD_examples = [
    "å—¯", "å¥½å“¦", "çŸ¥é“äº†", "ä¸ä¸€å®šå“¦", "éƒ½å¯ä»¥",
    "ä½ æ±ºå®šå§", "æˆ‘ç¾åœ¨ä¸æƒ³èŠ", "æ²’ä»€éº¼", "éš¨ä¾¿", "..."
]

# ä¸æƒ³è¦‹é¢ IOD
meeting_iod_examples = [
    "å†çœ‹çœ‹å§", 
    "æˆ‘å†æƒ³æƒ³"
]

shit_test_examples = [
    "ä½ è©²ä¸æœƒåªæœƒèŠå¤©å§",
    "ä¹Ÿå°±é€™æ¨£å•Š",
    "ä½ æ˜¯ä¸æ˜¯å¾ˆå­¤å–®",
    "ä½ æ²’åˆ¥çš„æœ¬äº‹å—",
    "æˆ‘çœ‹ä½ å…¶å¯¦ä¹Ÿé‚„å¥½å˜›",
    "ä½ æ˜¯ä¸æ˜¯åœ¨ç‚«è€€å•Š",
    "ä¹Ÿæ²’å¤šå²å®³å˜›",
    "å°±é€™æ¨£ï¼Ÿ"
]

# **çˆ†ç‚¸èªéŒ„ï¼ˆèˆ”ç‹—èªéŒ„ï¼‰**
red_flags = [
    "æˆ‘å¯ä»¥ç‚ºä½ åšä»»ä½•äº‹",
    "å¦³é–‹å¿ƒå°±å¥½",
    "æˆ‘æ²’é—œä¿‚",
    "æˆ‘ä¸å€¼å¾—",
    "å°ä¸èµ·æˆ‘éŒ¯äº†",
    "å¦³æ˜¯æˆ‘çš„å…¨éƒ¨",
    "æ±‚å¦³äº†",
    "å¦³èªªä»€éº¼æˆ‘éƒ½è½",
    "åªè¦å¦³é–‹å¿ƒï¼Œæˆ‘ä»€éº¼éƒ½é¡˜æ„",
    "æ‹œè¨—å¦³ç†æˆ‘"
]

# **èŠè‰²è¡Œç‚ºï¼ˆNSFW èªéŒ„ï¼‰**
nsfw_flags = [
    "ä½ çš„èº«æå¥½è¾£", "ä½ ç©¿ä»€éº¼é¡è‰²çš„å…§è¡£", "æ™šä¸Šå¯ä»¥ä¾†æˆ‘å®¶å—", "æˆ‘å€‘ä¾†é»åˆºæ¿€çš„", "ä½ ç¡è¦ºæœƒç©¿ä»€éº¼",
    "è¦ä¸è¦ä¸€èµ·æ´—æ¾¡", "å¦³æ˜¯ä¸æ˜¯å¾ˆé¨·", "æˆ‘å€‘ç›´æ¥é–‹æˆ¿å§", "ä»Šæ™šè¦ä¸è¦ä¾†é»ç‰¹åˆ¥çš„"
]

# **ç²å– Embeddings**
def get_embedding(text):
    """ä½¿ç”¨ OpenAI çš„ text-embedding-ada-002 è½‰æ›æ–‡å­—ç‚ºå‘é‡"""
    response = openai.Embedding.create(
        input=text,
        model="text-embedding-ada-002"
    )
    return np.array(response["data"][0]["embedding"])

# **é å…ˆè¨ˆç®— IOI/IOD å‘é‡**
IOI_embeddings = {phrase: get_embedding(phrase) for phrase in IOI_examples}
IOD_embeddings = {phrase: get_embedding(phrase) for phrase in IOD_examples}
meeting_IOD_embeddings = {phrase: get_embedding(phrase) for phrase in meeting_iod_examples}
red_flag_embeddings = {phrase: get_embedding(phrase) for phrase in red_flags}
nsfw_embeddings = {phrase: get_embedding(phrase) for phrase in nsfw_flags}
shit_test_embeddings = {phrase: get_embedding(phrase) for phrase in shit_test_examples}

# **è¨˜éŒ„å°è©±æ­·å²**
conversation_history = deque(maxlen=10)  # åªè¨˜éŒ„æœ€è¿‘ 10 æ¬¡å°è©±
no_reply_count = 0  # è¨˜éŒ„å¥³ç”Ÿä¸å›æ‡‰çš„å¤©æ•¸

def cosine_similarity(vec1, vec2):
    """è¨ˆç®—é¤˜å¼¦ç›¸ä¼¼åº¦"""
    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))

# è®€å– 37 å¥—èŠå¤©æ¡ˆä¾‹
with open("chat_cases.json", "r", encoding="utf-8") as file:
    chat_cases = json.load(file)

# å°‡ 37 å¥—æ¡ˆä¾‹è½‰æˆä¸€å€‹é•· Promptï¼Œè®“ AI è¨˜ä½ä¸¦æ¨¡ä»¿
case_prompt = "ä½ æ˜¯ä¸€ä½æˆ€æ„›é«˜æ‰‹ï¼Œå°ˆé–€æŒ‡å°ç”·ç”ŸèŠå¤©ã€‚è«‹åš´æ ¼æŒ‰ç…§ä»¥ä¸‹ 37 å¥—èŠå¤©æ¡ˆä¾‹çš„é¢¨æ ¼ä¾†å›æ‡‰ä»»ä½•å¥³ç”Ÿçš„å°è©±ã€‚\n\n"
for i, case in enumerate(chat_cases, 1):
    case_prompt += f"æ¡ˆä¾‹ {i}:\n"
    for d in case["dialogue"]:
        case_prompt += f"{d['role']}: {d['content']}\n"
    case_prompt += "\n"

def classify_response(response_text):
    """åˆ¤æ–·å¥³ç”Ÿå›æ‡‰æ˜¯ IOIï¼ˆæœ‰èˆˆè¶£ï¼‰é‚„æ˜¯ IODï¼ˆæ²’èˆˆè¶£ï¼‰"""
    response_embedding = get_embedding(response_text)
    
    max_ioi_sim = max([cosine_similarity(response_embedding, emb) for emb in IOI_embeddings.values()])
    max_iod_sim = max([cosine_similarity(response_embedding, emb) for emb in IOD_embeddings.values()])
    max_meeting_iod_sim = max([cosine_similarity(response_embedding, emb) for emb in meeting_IOD_embeddings.values()])
    max_shit_test_sim = max([cosine_similarity(response_embedding, emb) for emb in shit_test_embeddings.values()])
    
    # å…ˆåˆ¤æ–· Shit Test
    if max_shit_test_sim > 0.85:
        return "SHIT_TEST"

    # ä¾åºåˆ¤æ–· IOI / IOD / MEETING_IOD / ä¸­æ€§
    if max_ioi_sim > 0.85:
        return "IOI" # ï¼ˆå¥³ç”Ÿå°ä½ æœ‰èˆˆè¶£ï¼‰
    elif max_iod_sim > 0.85:
        return "IOD" # ï¼ˆå¥³ç”Ÿå°ä½ æ²’èˆˆè¶£ï¼‰
    elif max_meeting_iod_sim > 0.85:
        return "MEETING IOD" # (å¥³ç”Ÿå°ä½ æ²’èˆˆè¶£)
    else:
        return "ä¸­æ€§" # ï¼ˆç„¡æ³•ç¢ºå®šï¼‰

def analyze_conversation_trend():
    """åˆ†æé•·æœŸ IOI/IOD è¶¨å‹¢"""
    ioi_count = sum(1 for msg in conversation_history if "IOI" in msg)
    iod_count = sum(1 for msg in conversation_history if "IOD" in msg)

    if iod_count >= 2:
        return "æ¸¬è©¦ï¼šå¥³ç”Ÿé€£çºŒå…©æ¬¡å†·æ·¡å›æ‡‰ï¼Œè«‹ç›´æ¥è©¢å•å¥¹çš„çœŸå¯¦æƒ³æ³•" 
    elif ioi_count > iod_count:
        return "è¶¨å‹¢ï¼šå¥³ç”Ÿå°ä½ æœ‰èˆˆè¶£ï¼Œç¹¼çºŒæ¨é€²ï¼"
    elif iod_count > ioi_count:
        return "è¶¨å‹¢ï¼šå¥³ç”Ÿå°ä½ å†·æ·¡ï¼Œå¯èƒ½è¦èª¿æ•´ç­–ç•¥ï¼"
    else:
        return "è¶¨å‹¢ï¼šå¥³ç”Ÿåæ‡‰ä¸€èˆ¬ï¼Œä¿æŒæ¡†æ¶ï¼Œè§€å¯Ÿè®ŠåŒ–ã€‚"
    
# **æ¸¬è©¦å°è©±**
test_responses = [
    "ä½ é€±æœ«æœ‰ç©ºå—",  # IOI
    "æˆ‘å†çœ‹çœ‹å§",  # IOD
    "å“ˆå“ˆå“ˆ",  # IOI
    "éš¨ä¾¿",  # IOD
    "å—¯"  # IOD
]

for response in test_responses:
    result = classify_response(response)
    conversation_history.append(result)
    print(f"å¥³ç”Ÿï¼š{response}")
    print(f"åˆ†æçµæœï¼š{result}")
    
# **æŸ¥çœ‹é•·æœŸè¶¨å‹¢**
print(analyze_conversation_trend())

def is_exploded(response_text):
    """åˆ¤æ–·ç”·ç”Ÿæ˜¯å¦éåº¦è¿åˆï¼ˆèˆ”ç‹—è¡Œç‚ºï¼‰"""
    response_embedding = get_embedding(response_text)  # è½‰æ›ç”¨æˆ¶è¼¸å…¥æˆå‘é‡
    
    for phrase, flag_embedding in red_flag_embeddings.items():
        if cosine_similarity(response_embedding, flag_embedding) > 0.85:
            return "èˆ”ç‹—çˆ†ç‚¸ï¼ğŸ”¥ ä¸è¦æŠŠçªä¸¸æ”¾åˆ°å¥³ç”Ÿæ‰‹ä¸Šï¼Œä¿æŒæ¡†æ¶ï¼"

    for phrase, flag_embedding in nsfw_embeddings.items():
        if cosine_similarity(response_embedding, flag_embedding) > 0.85:
            return "ä½ çˆ†äº†ï¼ğŸ”¥ ä¸è¦æ€¥è‘—èŠè‰²ï¼Œé€™æ¨£æœƒæ‰åƒ¹ï¼"
        
    return None  # æ²’æœ‰çˆ†ç‚¸

def handle_no_reply():
    """è™•ç†å¥³ç”Ÿä¸å›æ‡‰çš„æƒ…æ³"""
    global no_reply_count
    no_reply_count += 1

    if no_reply_count == 1:
        return "ä¸ç†äººï¼Ÿ"
    elif no_reply_count >= 2:
        return "ç­‰å¹¾å¤©å¾Œå†æ‰¾å¥¹ï¼Œä¸è¦æ€¥è‘—å‚¬å¥¹ã€‚"
    return ""

def generate_soi():
    """ç”¢ç”Ÿ SOIï¼ˆè¡¨æ˜æ„åœ–ï¼‰"""
    value_statements = [
        "å‰›é–‹å®Œæœƒï¼Œ",
        "ä»Šå¤©å¥èº«å®Œè¶…ç´¯ï¼Œ",
        "æˆ‘å‰›è©¦äº†ä¸€å®¶æ–°é¤å»³ï¼Œ"
    ]
    return np.random.choice(value_statements) + " æ™šé»ä¸€èµ·åƒå€‹é£¯ï¼Ÿ"

# === ä»¥ä¸‹ç‚ºå‡ç¤ºç¯„å‡½å¼ï¼Œå¯¦éš›ä¸Šä½ æœ‰è‡ªå·±çš„å¯¦ä½œ ===

def detect_no_self_worth(user_input):
    """
    åµæ¸¬å¥³ç”Ÿæ˜¯å¦ã€Œæ²’æœ‰é…å¾—æ„Ÿã€çš„ç°¡æ˜“ç¤ºç¯„ï¼Œ
    ä¾‹å¦‚å¥³ç”Ÿèªªã€Œæˆ‘å¥½é†œã€ã€Œæˆ‘ä¸å€¼å¾—ã€ç­‰ã€‚
    """
    no_self_worth_phrases = ["æˆ‘å¾ˆé†œ", "æˆ‘ä¸å€¼å¾—", "é…ä¸ä¸Š", "æˆ‘ä»€éº¼éƒ½ä¸æœƒ"]
    return any(phrase in user_input for phrase in no_self_worth_phrases)

def generate_ioi_response(no_self_worth, user_input):
    """
    å‘¼å« OpenAI ChatCompletionï¼Œè®“ AI æ ¹æ“š no_self_worth æ±ºå®šè¦çµ¦ 'å¼· IOI' é‚„æ˜¯ 'å¼± IOI'
    """

    system_message = """
ä½ æ˜¯ä¸€ä½æˆ€æ„›æ•™ç·´ï¼Œè«‹ç”¢ç”Ÿä¸€æ®µå›æ‡‰çµ¦å¥³ç”Ÿã€‚ 
- å¦‚æœ no_self_worth = Trueï¼Œè¡¨ç¤ºå¥³ç”Ÿé…å¾—æ„Ÿå¾ˆä½ï¼Œéœ€è¦ä½ çµ¦ "å¼· IOI" ä¾†å¸¶é ˜å¥¹ï¼Œä¸¦é©åº¦å®‰æ’«æˆ–é¼“å‹µå¥¹ã€‚
- å¦‚æœ no_self_worth = Falseï¼Œè¡¨ç¤ºæ­£å¸¸ç‹€æ…‹ï¼Œä½ åªéœ€è¦çµ¦ 'å¼± IOI'ï¼Œä¸è¦è¡¨ç¾å¾—æ¯”å°æ–¹æ›´ç†±æƒ…ã€‚
- å›æ‡‰é¢¨æ ¼åƒè€ƒä½ çš„ 37 å¥—èŠå¤©æ¡ˆä¾‹ï¼Œèªæ°£è‡ªç„¶ï¼Œä¸è¦éåº¦æµ®èª‡ï¼Œä¹Ÿä¸è¦èˆ”ç‹—ã€‚
"""

    user_prompt = f"""
å¥³ç”Ÿçš„è¨Šæ¯: {user_input}
no_self_worth = {no_self_worth}

è«‹ç”¨ 1~2 å¥è©±ï¼Œçµ¦å‡ºå°æ‡‰çš„ IOI å›æ‡‰ï¼š
- å¼· IOIï¼šå±•ç¾æ›´é«˜çš„ç†±æƒ…å’Œå¸¶é ˜æ„Ÿ
- å¼± IOIï¼šä¿æŒè¼•é¬†æœ‰è¶£ï¼Œä½†ä¸æœƒéåº¦ç†±æƒ…
"""

    messages = [
        {"role": "system", "content": system_message},
        {"role": "user", "content": user_prompt}
    ]

    response = openai.ChatCompletion.create(
        model="gpt-4o",     # ä½ å¯¦éš›ä½¿ç”¨çš„æ¨¡å‹
        messages=messages,
        temperature=0.7,    # å¯è‡ªè¡Œèª¿æ•´
    )

    ai_response = response["choices"][0]["message"]["content"]
    return ai_response

def generate_iod_response(user_input):
    """
    è®“ AI ç”¢ç”Ÿä¸€å€‹ã€Œä½æŠ•è³‡ã€ä¿æŒæ¡†æ¶ã€çš„å›æ‡‰ã€‚
    ä½¿ç”¨ ChatCompletionã€æ­é… 37 å¥—èŠå¤©æ¡ˆä¾‹é¢¨æ ¼ã€‚
    """

    system_message = """
ä½ æ˜¯ä¸€ä½æˆ€æ„›æ•™ç·´ï¼Œç•¶å¥³ç”Ÿå›æ‡‰å†·æ·¡ (IOD) æ™‚ï¼Œ
ä½ è¦ç¶­æŒæ¡†æ¶ã€ä¸è¦éåº¦æŠ•è³‡ï¼Œä¹Ÿä¸è¦é¡¯å¾—è¨å¥½æˆ–ç”Ÿæ°£ã€‚
è«‹åƒè€ƒ 37 å¥—èŠå¤©æ¡ˆä¾‹çš„é¢¨æ ¼ï¼Œèªæ°£è‡ªç„¶ï¼Œç°¡çŸ­æœ‰ç¦®ã€‚
"""

    user_prompt = f"""
å¥³ç”Ÿçš„è¨Šæ¯: {user_input}
å¥¹çš„å›æ‡‰æ˜¯ IODï¼ˆå†·æ·¡æŒ‡æ¨™ï¼‰ï¼Œè«‹ç”¨ 1~2 å¥è©±å›æ‡‰å¥¹ï¼Œ
ä¿æŒç¦®è²Œåˆä¸å¤±æ¡†æ¶ï¼Œèªæ°£ä¸è¦éåº¦ç†±æƒ…ã€‚
"""

    messages = [
        {"role": "system", "content": case_prompt + "\n\n" + system_message},
        {"role": "user", "content": user_prompt}
    ]

    response = openai.ChatCompletion.create(
        model="gpt-4o",     # ä½ çš„Chatæ¨¡å‹
        messages=messages,
        temperature=0.5     # å¯è‡ªè¡Œèª¿æ•´ï¼šæº«åº¦ä½â†’æ›´åš´è¬¹ç©©å®š
    )
    
    ai_response = response["choices"][0]["message"]["content"]
    return ai_response

def generate_shit_test_response(user_input):
    """
    è®“ AI ç”¢ç”Ÿé‡å°ã€å»¢ç‰©æ¸¬è©¦ã€(Shit Test) çš„å¹½é»˜å›æ‡‰ã€‚
    ä¸è¦æ‰åƒ¹ï¼Œä¸è¦è¢«æ¿€æ€’ï¼Œèƒ½é©åº¦å±•ç¾è‡ªä¿¡ã€‚
    """

    system_message = """
ä½ æ˜¯ä¸€ä½æˆ€æ„›æ•™ç·´ï¼Œç•¶å¥³ç”Ÿå°ä½ é€²è¡Œ 'å»¢ç‰©æ¸¬è©¦(Shit Test)'ï¼Œä½ è¦ç”¨å¹½é»˜ã€è‡ªä¿¡çš„æ–¹å¼æ‡‰å°ã€‚
- ä¸è¦éåº¦è§£é‡‹æˆ–é“æ­‰
- ä¸è¦å‘å¾®ï¼Œç¶­æŒæ¡†æ¶
- èªæ°£å¯è¼•é¬†åå•æˆ–å¸¶é»èª¿ä¾ƒï¼Œè®“å¥³ç”Ÿæ„Ÿåˆ°æœ‰è¶£
- è«‹åƒè€ƒ 37 å¥—èŠå¤©æ¡ˆä¾‹é¢¨æ ¼ï¼Œä¸è¦éåº¦æ”»æ“Šæˆ–æƒ…ç·’åŒ–
"""

    user_prompt = f"""
å¥³ç”Ÿçš„è¨Šæ¯: {user_input}
å¥¹å°ä½ æœ‰äº›æŒ‘é‡æˆ–å˜²è«·ï¼Œä½ è¦å¦‚ä½•å›æ‡‰æ‰ä¸é¡¯å¾—æ‰åƒ¹ï¼Ÿ
è«‹ç”¨ 1~2 å¥è©±å±•ç¾å¹½é»˜èˆ‡è‡ªä¿¡ã€‚
"""

    messages = [
        {"role": "system", "content": case_prompt + "\n\n" + system_message},
        {"role": "user", "content": user_prompt}
    ]

    response = openai.ChatCompletion.create(
        model="gpt-4o",
        messages=messages,
        temperature=0.7
    )
    
    ai_response = response["choices"][0]["message"]["content"]
    return ai_response

def chat_coach(user_input):
    """
    AI ä¾ç…§ 37 å¥—èŠå¤©æ¡ˆä¾‹çš„é¢¨æ ¼å›æ‡‰ã€‚
    ç•¶å¥³ç”Ÿé¡¯ç¤º IOI æ™‚ï¼Œç”± AI è‡ªè¡Œåˆ¤æ–·ã€ŒçœŸIOI / å‡IOIã€ï¼Œä¸¦æ±ºå®šå›æ‡‰ã€Œå¼±IOI / å¼·IOIã€ã€‚
    é™¤éåµæ¸¬åˆ°å¥³ç”Ÿæ²’æœ‰é…å¾—æ„Ÿï¼Œæ‰çµ¦å¼·IOIï¼Œå¦å‰‡é è¨­çµ¦å¼±IOIã€‚
    å…¶é¤˜ IOD / ä¸­æ€§ ä»æŒ‰åŸé‚è¼¯è™•ç†ã€‚
    """
    
    # 1. åµæ¸¬çˆ†ç‚¸ï¼ˆèˆ”ç‹— or èŠè‰²ï¼‰
    explosion = is_exploded(user_input)
    if explosion:
        return explosion
    
    # 2. å¦‚æœå¥³ç”Ÿæ²’è¼¸å…¥ä»»ä½•æ±è¥¿(ç©ºå­—ä¸²)ï¼Œè™•ç†ä¸å›æ‡‰
    if user_input.strip() == "":
        return handle_no_reply()
    
    # 3. åˆ†æé€™æ¬¡å¥³ç”Ÿè¨Šæ¯æ˜¯ IOI / IOD / ä¸­æ€§
    cls_result = classify_response(user_input)
    conversation_history.append(cls_result)

    # ç¤ºç¯„ï¼šå½ä»£ç¢¼ - å‡è¨­æˆ‘å€‘æœ‰ä»¥ä¸‹è³‡è¨Š
    #   - no_self_worth: æ˜¯å¦åµæ¸¬åˆ°å¥³ç”Ÿã€Œæ²’æœ‰é…å¾—æ„Ÿã€ (True / False)
    no_self_worth = detect_no_self_worth(user_input)  # ä½ å¯ä»¥è‡ªè¡Œå¯¦ä½œ
    
    #   - case_prompt: ä½ åŸæœ¬çš„ 37 å¥—èŠå¤©æ¡ˆä¾‹ Prompt
    #   - å…¶é¤˜å¯ä¾éœ€æ±‚æ·»åŠ 
    
    # **æª¢æŸ¥å°è©±æ­·å²ä¾†åˆ¤æ–·æ•´é«”è¶¨å‹¢**
    ioi_count = sum(1 for msg in conversation_history if msg == "IOI")
    iod_count = sum(1 for msg in conversation_history if msg == "IOD")
    
    # **å¦‚æœå¥³ç”Ÿé€£çºŒå…©æ¬¡èªªã€Œå†çœ‹çœ‹å§ã€ï¼Œç›´æ¥æ¸¬è©¦å¥¹**
    if conversation_history.count("MEETING_IOD") >= 2:
        return "ä½ æ˜¯ä¸å¤ªæƒ³å’Œæˆ‘è¦‹é¢å—ï¼Ÿ"
    
    # **è™•ç†å¥³ç”Ÿä¸å›æ‡‰**
    if user_input.strip() == "":
        return handle_no_reply()
    
    # **ç”¢ç”Ÿ SOI**
    if np.random.rand() > 0.8:  # å¶çˆ¾åŠ å…¥ SOI
        return generate_soi()
    
    # **è™•ç† IOIï¼ˆèˆˆè¶£æŒ‡æ¨™ï¼‰**
    if cls_result == "IOI":
        # é€™è£¡å‘¼å« OpenAI APIï¼Œè®“ AI æ±ºå®šè©²å›ã€Œå¼· IOIã€æˆ–ã€Œå¼± IOIã€
        return generate_ioi_response(no_self_worth, user_input)
    
    # **è™•ç† IODï¼ˆå†·æ·¡æŒ‡æ¨™ï¼‰**
    elif cls_result == "IOD":
        # è®“ AI å‹•æ…‹ç”Ÿæˆã€Œå†·æ·¡å›æ‡‰ã€
        return generate_iod_response(user_input)
    
    """è®“ AI ä¾ç…§ 37 å¥—èŠå¤©æ¡ˆä¾‹çš„é¢¨æ ¼å›æ‡‰ï¼Œä¸¦åˆ¤æ–·æ˜¯å¦çˆ†äº†"""
    response = openai.ChatCompletion.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": case_prompt},
            {"role": "user", "content": user_input}
        ]
    )
    
    ai_response = response["choices"][0]["message"]["content"]

    return ai_response

# æ¸¬è©¦å¥³ç”Ÿçš„å›æ‡‰
examples = [
    "ä»Šå¤©æœ‰é»ç´¯è€¶ğŸ˜©",  # AI å¿…é ˆç”¨ 37 å¥—æ¡ˆä¾‹çš„æ–¹å¼å›æ‡‰
    "æœ€è¿‘å¥½ç„¡èŠå–”ğŸ˜",
    "å¥½åƒå¾ˆä¹…æ²’å‡ºå»ç©äº†ğŸ¤”",
    "å¦³é–‹å¿ƒå°±å¥½ï¼Œæˆ‘æ²’é—œä¿‚ğŸ¥º",  # æ¸¬è©¦çˆ†ç‚¸è¡Œç‚º
    "å¦³èªªä»€éº¼æˆ‘éƒ½è½ï¼Œå¦³æ˜¯æˆ‘çš„å…¨éƒ¨ğŸ¥º"
]

for example in examples:
    print(f"å¥³ç”Ÿï¼š{example}")
    print(f"æˆ€æ„›æ•™ç·´ AIï¼š{chat_coach(example)}\n")


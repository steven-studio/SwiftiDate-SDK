import openai
import json
import numpy as np
from collections import deque

from embedding_utils import (
    get_embedding,
    cosine_similarity,
    red_flag_embeddings,
    nsfw_embeddings,
)
from prompt_generators import (
    generate_soi,
    generate_ioi_response,
    generate_iod_response,
)

# === å…¨åŸŸè®Šæ•¸ ===
IS_GIRL_INITIATED = False  # è¡¨ç¤ºå¥³ç”Ÿæ˜¯å¦æœ‰ã€Œä¸»å‹•é–‹è©±é¡Œã€çš„ç‹€æ…‹
conversation_history = deque(maxlen=10)  # è¨˜éŒ„æœ€è¿‘ 10 æ¬¡å°è©±åˆ†é¡çµæœ
no_reply_count = 0  # è¨˜éŒ„å¥³ç”Ÿä¸å›æ‡‰çš„æ¬¡æ•¸

# === 37 å¥—èŠå¤©æ¡ˆä¾‹æ‰€çµ„æˆçš„ Prompt ===
case_prompt = (
    "ä½ æ˜¯ä¸€ä½æˆ€æ„›é«˜æ‰‹ï¼Œå°ˆé–€æŒ‡å°ç”·ç”ŸèŠå¤©ã€‚"
    "è«‹åš´æ ¼æŒ‰ç…§ä»¥ä¸‹ 37 å¥—èŠå¤©æ¡ˆä¾‹çš„é¢¨æ ¼ä¾†å›æ‡‰ä»»ä½•å¥³ç”Ÿçš„å°è©±ã€‚\n\n"
)

# === åˆ¤æ–·æ˜¯å¦å¥³ç”Ÿä¸»å‹•çš„ç¯„ä¾‹å‡½å¼ ===
def should_mark_girl_initiated(user_input: str) -> bool:
    """
    ä¾æ“šæŸäº›æ¢ä»¶ï¼Œåˆ¤æ–·å¥³ç”Ÿæ˜¯å¦ä¸»å‹•ã€‚
    ä»¥ä¸‹ç¤ºç¯„ï¼šè‹¥å°è©±æ­·å²ç‚ºç©º (è¡¨ç¤ºå‰›é–‹å§‹),
    æˆ–æœ¬å°ˆæ¡ˆè¦å‰‡(å¯è‡ªè¡Œæ“´å……),
    å°±æ¨™è¨˜ Trueã€‚
    """
    if len(conversation_history) == 0:
        return True
    # å…¶ä»–é‚è¼¯äº¦å¯è‡ªè¡Œæ“´å……
    return False

def is_exploded(response_text: str) -> str or None: # type: ignore
    """åˆ¤æ–·ç”·ç”Ÿæ˜¯å¦éåº¦è¿åˆï¼ˆèˆ”ç‹—è¡Œç‚ºï¼‰æˆ–èŠè‰²çˆ†ç‚¸"""
    response_embedding = get_embedding(response_text)  # è½‰æ›ç”¨æˆ¶è¼¸å…¥æˆå‘é‡
    
    for phrase, flag_embedding in red_flag_embeddings.items():
        if cosine_similarity(response_embedding, flag_embedding) > 0.85:
            return "èˆ”ç‹—çˆ†ç‚¸ï¼ğŸ”¥ ä¸è¦æŠŠçªä¸¸æ”¾åˆ°å¥³ç”Ÿæ‰‹ä¸Šï¼Œä¿æŒæ¡†æ¶ï¼"

    for phrase, flag_embedding in nsfw_embeddings.items():
        if cosine_similarity(response_embedding, flag_embedding) > 0.85:
            return "ä½ çˆ†äº†ï¼ğŸ”¥ ä¸è¦æ€¥è‘—èŠè‰²ï¼Œé€™æ¨£æœƒæ‰åƒ¹ï¼"
        
    return None  # æ²’æœ‰çˆ†ç‚¸

def handle_no_reply() -> str:
    """è™•ç†å¥³ç”Ÿä¸å›æ‡‰çš„æƒ…æ³"""
    global no_reply_count
    no_reply_count += 1

    if no_reply_count == 1:
        return "ä¸ç†äººï¼Ÿ"
    elif no_reply_count >= 2:
        return "ç­‰å¹¾å¤©å¾Œå†æ‰¾å¥¹ï¼Œä¸è¦æ€¥è‘—å‚¬å¥¹ã€‚"
    return ""

def detect_no_self_worth(user_input: str) -> bool:
    """
    åµæ¸¬å¥³ç”Ÿæ˜¯å¦ã€Œæ²’æœ‰é…å¾—æ„Ÿã€çš„ç°¡æ˜“ç¤ºç¯„ï¼Œ
    ä¾‹å¦‚å¥³ç”Ÿèªªã€Œæˆ‘å¥½é†œã€ã€Œæˆ‘ä¸å€¼å¾—ã€ç­‰ã€‚
    """
    no_self_worth_phrases = ["æˆ‘å¾ˆé†œ", "æˆ‘ä¸å€¼å¾—", "é…ä¸ä¸Š", "æˆ‘ä»€éº¼éƒ½ä¸æœƒ"]
    return any(phrase in user_input for phrase in no_self_worth_phrases)

# === ä»¥ä¸‹å››å€‹è®Šæ•¸/Embeddingsï¼Œå¯åœ¨å…¶ä»–æª”æ¡ˆ (e.g. constants.py æˆ– embedding_utils.py) å®šç¾©å¾Œ import ===
# é€™è£¡å‡è¨­ä½ å·²ç¶“åœ¨åˆ¥è™•å®šç¾©ï¼š
#   IOI_embeddings, IOD_embeddings, meeting_IOD_embeddings, shit_test_embeddings

def classify_response(response_text: str) -> str:
    """
    åˆ¤æ–·å¥³ç”Ÿå›æ‡‰æ˜¯:
    - SHIT_TEST
    - IOI (æœ‰èˆˆè¶£)
    - IOD (å†·æ·¡)
    - MEETING IOD (ä¸æƒ³è¦‹é¢)
    - ä¸­æ€§
    """
    from embedding_utils import (
        IOI_embeddings, IOD_embeddings,
        meeting_IOD_embeddings, shit_test_embeddings,
    )
    response_embedding = get_embedding(response_text)
    
    max_ioi_sim = max(
        cosine_similarity(response_embedding, emb)
        for emb in IOI_embeddings.values()
    )
    max_iod_sim = max(
        cosine_similarity(response_embedding, emb)
        for emb in IOD_embeddings.values()
    )
    max_meeting_iod_sim = max(
        cosine_similarity(response_embedding, emb)
        for emb in meeting_IOD_embeddings.values()
    )
    max_shit_test_sim = max(
        cosine_similarity(response_embedding, emb)
        for emb in shit_test_embeddings.values()
    )
    
    # å…ˆåˆ¤æ–· Shit Test
    if max_shit_test_sim > 0.85:
        return "SHIT_TEST"

    # ä¾åºåˆ¤æ–· IOI / IOD / MEETING_IOD / ä¸­æ€§
    if max_ioi_sim > 0.85:
        return "IOI" # ï¼ˆå¥³ç”Ÿå°ä½ æœ‰èˆˆè¶£ï¼‰
    elif max_iod_sim > 0.85:
        return "IOD" # ï¼ˆå¥³ç”Ÿå°ä½ æ²’èˆˆè¶£ï¼‰
    elif max_meeting_iod_sim > 0.85:
        return "MEETING IOD" # (å¥³ç”Ÿå°ä½ æ²’èˆˆè¶£)
    else:
        return "ä¸­æ€§" # ï¼ˆç„¡æ³•ç¢ºå®šï¼‰

def chat_coach(user_input: str) -> str:
    """
    AI ä¾ç…§ 37 å¥—èŠå¤©æ¡ˆä¾‹çš„é¢¨æ ¼å›æ‡‰ã€‚
    ç•¶å¥³ç”Ÿé¡¯ç¤º IOI æ™‚ï¼Œç”± AI è‡ªè¡Œåˆ¤æ–·ã€ŒçœŸIOI / å‡IOIã€ï¼Œä¸¦æ±ºå®šå›æ‡‰ã€Œå¼±IOI / å¼·IOIã€ã€‚
    é™¤éåµæ¸¬åˆ°å¥³ç”Ÿæ²’æœ‰é…å¾—æ„Ÿï¼Œæ‰çµ¦å¼·IOIï¼Œå¦å‰‡é è¨­çµ¦å¼±IOIã€‚
    å…¶é¤˜ IOD / ä¸­æ€§ ä»æŒ‰åŸé‚è¼¯è™•ç†ã€‚
    """

    global IS_GIRL_INITIATED

    # 1. åµæ¸¬çˆ†ç‚¸ï¼ˆèˆ”ç‹— or èŠè‰²ï¼‰
    explosion = is_exploded(user_input)
    if explosion:
        return explosion
    
    # 2. å¦‚æœå¥³ç”Ÿæ²’è¼¸å…¥ä»»ä½•æ±è¥¿(ç©ºå­—ä¸²)ï¼Œè™•ç†ä¸å›æ‡‰
    if user_input.strip() == "":
        return handle_no_reply()
    
    # 3. åˆ¤æ–·å¥³ç”Ÿæ˜¯å¦ä¸»å‹•
    if should_mark_girl_initiated(user_input):
        IS_GIRL_INITIATED = True
    
    # 4. åˆ†æå›æ‡‰é¡å‹
    cls_result = classify_response(user_input)
    conversation_history.append(cls_result)

    # 5. è‹¥é€£çºŒå…©æ¬¡ "MEETING_IOD"
    if conversation_history.count("MEETING_IOD") >= 2:
        return "ä½ æ˜¯ä¸å¤ªæƒ³å’Œæˆ‘è¦‹é¢å—ï¼Ÿ"

    # **æª¢æŸ¥å°è©±æ­·å²ä¾†åˆ¤æ–·æ•´é«”è¶¨å‹¢**
    ioi_count = sum(1 for msg in conversation_history if msg == "IOI")
    iod_count = sum(1 for msg in conversation_history if msg == "IOD")
    
    # 6. ç¢°åˆ°ç©ºå­—ä¸²ä¹Ÿå†æ¬¡æª¢æŸ¥(ä»¥é˜²é‚è¼¯)
    if user_input.strip() == "":
        return handle_no_reply()
    
    # 7. éš¨æ©Ÿæ©Ÿç‡åŠ å…¥ SOI
    if np.random.rand() > 0.8:  # å¶çˆ¾åŠ å…¥ SOI
        return generate_soi()
    
    # 8. æ ¹æ“šåˆ†é¡çµæœæ±ºå®šå›æ‡‰
    no_self_worth = detect_no_self_worth(user_input)  # ä½ å¯ä»¥è‡ªè¡Œå¯¦ä½œ
    if cls_result == "IOI":
        # é€™è£¡å‘¼å« OpenAI APIï¼Œè®“ AI æ±ºå®šè©²å›ã€Œå¼· IOIã€æˆ–ã€Œå¼± IOIã€
        return generate_ioi_response(no_self_worth, user_input)
    elif cls_result == "IOD":
        # è®“ AI å‹•æ…‹ç”Ÿæˆã€Œå†·æ·¡å›æ‡‰ã€
        return generate_iod_response(user_input)
    
    # 9. å¦‚æœéƒ½ä¸ç¬¦åˆ (å«ã€Œä¸­æ€§ã€or å…¶ä»–)
    #   å°±ç”¨æœ€åˆçš„ system prompt è®“ GPT-4o ç”¢ç”Ÿå›è¦†
    response = openai.ChatCompletion.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": case_prompt},
            {"role": "user", "content": user_input}
        ]
    )
    
    return response["choices"][0]["message"]["content"]